DATASET: LatinBHO
DATA_LOADER:
  NUM_THREADS: 12
MODEL:
  STYLE_ENCODER_LAYERS: 3
  NUM_IMGS: 15
  IN_CHANNELS: 4
  OUT_CHANNELS: 4
  NUM_RES_BLOCKS: 1
  NUM_HEADS: 4
  EMB_DIM: 512
SOLVER:
  BASE_LR: 0.00002  # Further reduced to prevent model collapse (was 0.00005)
  EPOCHS: 2000
  WARMUP_ITERS: 20000
  TYPE: AdamW
  GRAD_L2_CLIP: 1.0  # Tighter gradient clipping for stability
  DIVERSITY_WEIGHT: 0.03  # Moderate weight - too high prevents learning, too low allows collapse
  DIVERSITY_MIN_VARIANCE: 0.1  # Lower threshold to avoid penalizing early learning
  DIVERSITY_START_ITER: 5000  # Start applying diversity regularization after 5k iterations
TRAIN:
  TYPE: train
  IMS_PER_BATCH: 12  # Reduced from 16 to avoid GPU memory saturation (24 GB)
  IMG_H: 64
  IMG_W: 64
  IMAGE_PATH: data/LatinBHO/images
  STYLE_PATH: data/LatinBHO/style_images
  LABEL_PATH: data/LatinBHO/train.txt
  SNAPSHOT_ITERS: 500  # Save checkpoint every 500 iterations with test image
  SNAPSHOT_BEGIN: 0
  SEED: 1001
TEST:
  TYPE: test
  IMS_PER_BATCH: 8
  IMG_H: 64
  IMAGE_PATH: data/LatinBHO/images
  STYLE_PATH: data/LatinBHO/style_images
  LABEL_PATH: data/LatinBHO/test.txt

