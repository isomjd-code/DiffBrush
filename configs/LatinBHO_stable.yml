DATASET: LatinBHO
DATA_LOADER:
  NUM_THREADS: 12
MODEL:
  STYLE_ENCODER_LAYERS: 3
  NUM_IMGS: 15
  IN_CHANNELS: 4
  OUT_CHANNELS: 4
  NUM_RES_BLOCKS: 1
  NUM_HEADS: 4
  EMB_DIM: 512
SOLVER:
  BASE_LR: 0.00002  # Further reduced to prevent model collapse (was 0.00005)
  EPOCHS: 2000
  WARMUP_ITERS: 20000
  TYPE: AdamW
  GRAD_L2_CLIP: 1.0  # Tighter gradient clipping for stability
  DIVERSITY_WEIGHT: 0.03  # Moderate weight - too high prevents learning, too low allows collapse
  DIVERSITY_MIN_VARIANCE: 0.1  # Lower threshold to avoid penalizing early learning
  DIVERSITY_START_ITER: 5000  # Start applying diversity regularization after 5k iterations
TRAIN:
  TYPE: train
  IMS_PER_BATCH: 6  # Reduced due to PyLaia CTC loss + VAE decode memory overhead
  IMG_H: 64
  IMG_W: 64
  IMAGE_PATH: data/LatinBHO/images
  STYLE_PATH: data/LatinBHO/style_images
  LABEL_PATH: data/LatinBHO/train.txt
  SNAPSHOT_ITERS: 500  # Save checkpoint every 500 iterations with test image
  SNAPSHOT_BEGIN: 0
  SEED: 1001
# PyLaia readability supervisor settings
PYLAIA:
  ENABLED: true  # Enable PyLaia CTC loss for readability supervision
  # Use weights-only checkpoint (extracted without Lightning dependencies)
  CHECKPOINT: ../bootstrap_training_data/pylaia_models/model_v22/weights_only.pth
  SYMS_PATH: ../bootstrap_training_data/pylaia_models/model_v22/syms.txt
  INPUT_HEIGHT: 128  # PyLaia expects 128px height
  WEIGHT: 0.1  # Weight for CTC loss (0.01-0.1 recommended)
  START_ITER: 5000  # Start applying CTC loss after N iterations (model needs to learn basic shapes first)
  APPLY_EVERY: 32  # Apply CTC loss every N batches (high value for memory/speed)
TEST:
  TYPE: test
  IMS_PER_BATCH: 8
  IMG_H: 64
  IMAGE_PATH: data/LatinBHO/images
  STYLE_PATH: data/LatinBHO/style_images
  LABEL_PATH: data/LatinBHO/test.txt

